{
  "hash": "a504f64eaadee1d89ed8c412bdba4344",
  "result": {
    "engine": "julia",
    "markdown": "---\ntitle: \"Bayesian modeling in Julia: Turing and Stan\"\ncode-tools: true\ncode-fold: false\ncode-line-numbers: true\ndate: today\ncategories:\n  - julia\n  - bayesian\nexecute:\n    eval: false\nengine: julia\n---\n\nI've been using `Julia` more and more in my non-work projects. Years ago I had tried out `Julia` but found the syntax and the concepts pretty foreign.\nOver time, I've been exposed more and more to fundamental computer science concepts that have made seem increasingly approachable.\n\n`Julia`, relative to other languages designed for data science, certainly feels much less high-level than `Python` and `R`.\nAn obvious reason is that though `Julia` is a dynamically-typed language, it does not use an interpreter in the same way that `Python` and `R` does.\n`Julia` does not go as far as statically-typed and low-level languages such as `C++` where you write the code, save the file, and then compile it\nto be converted into the machine code that ultimately does the work. \n`Julia` instead leverages a `Just-In-Time` compiler that stores the machine code as you go along. This and a few other features of the JIT compiler\nit uses, `LLVM`, such as Multiple Dispatch, is the reason that many in the scientific computing and data science space have used it as their language\nof choice where one needs to maximize performance.\n\nAside from the need to understand some computer science concepts as a barrier, another was that I was more comfortable writing my Bayesian statistical\nmodels in `Stan` using either `cmdstanr` or `cmdstanpy`. These interfaces allowed me to take advantage of the power of `C++` and its wonderful memory management\nalong with `Stan`'s use of the No-U-Turn-Sampler for efficient and accurate `MCMC` inference while allowing me to keep using languages that I was comfortable with\nto do all of the other parts outside of fitting the model (i.e., data cleaning, visualizing the results, etc.). As my curiosity around `Julia` grew, I was still\ndetermined to stick with `Stan` due to my comfort with it and I didn't feel that there was as large of a community (therefore support) for `Stan` (and the NUTS sampler)\nin `Julia`. So, I stayed away.\n\nIn the past few months, I have been working on some academic projects in my free time and had seen that I could use the NUTS algorithm using `Turing.jl`.\nI haven't checked how long this algorithm has been available with `Turing.jl` and honestly I don't even remember looking for `Turing.jl` when I had been flirting\nwith the language in the past. I had just been looking for \"Stan in Julia\" and had not seen as much as I was accustomed to in `R` and `Python` circles.\nThat is, it was definitely my fault for not having looked into it deeper. But, I don't think I am alone in not seeing `Julia` as being competitive with `R` or even `Python`\nfor Bayesian modeling.\n\nA recent side project of mine has been to use Bradley-Terry models to power rank MLB teams. MLB teams are ranked by how many wins and losses they have. \nThe more teams relative to losses a team has, the higher their rankings are in the standings. The use of the Bradley-Terry model is to estimate the latent\nability of each of the teams. This is done by taking each team and their opponents. \nTo understand how difficult the opponents are, you look at the opponents' opponents and how they've faired against them.\nTeams that may have the same number of wins and losses may be equal in the standings, but if one team has beaten more teams with better records than the other team\nthat has beaten fewer teams with better records, then the former team is the one that would have a better latent ability than the latter team.\n\nWhen I had first been playing around with these models, I was doing it in `Python` with `cmdstanpy`. However, recently, I thought I'd try it out using `Turing.jl`.\nOne reason was out of curiosity about how it'd perform against `cmdstanpy`. The other reason was that I had been toying around the idea for a larger project where\nI write a web app to do some Bayesian modeling with a `Julia` backend and thought that I should also try to fit the models using `Turing.jl` rather than do a `Python`\nbackend or to use straight-up `cmdstan`.\n\nSo, I wrote re-wrote the models that I had in `cmdstanpy` and implemented them in `Turing.jl`. I posted a picture of my terminal on Bluesky and Elliott Morris was\namazed, like I had been, that `Turing.jl` had NUTS available as the MCMC sampler. He then asked for a blog post comparing between them. I am but a humble servant.\n\nTo make apples-to-apples comparisons between `Turing.jl` and `cmdstan` benchmarks, I use `Stan.jl` using `Stan 2.38.0` and `Turing.jl` on my [DETAILS ABOUT COMPUTER HERE]\nand I look at how they do!\n\nLet's first load some packages.\n\n::: {#2 .cell execution_count=0}\n``` {.julia .cell-code}\nusing DataFrames;\nusing DuckDB;\nusing Stan;\nusing Turing;\n```\n:::\n\n\n\nThen I am going to connect to my local database (from the project that this was inspired from) and pull in the data.\n\n::: {#4 .cell execution_count=0}\n``` {.julia .cell-code}\n# Connect to the DB.\ncon = DBInterface.connect(DuckDB.DB, \"~/Desktop/mlb_pred/data/twenty_five.db\");\n# Pull in the data as a dataframe.\ndf = DataFrame(\n    DBInterface.execute(\n        con \n        , \"\"\"\n        with a as (\n            select\n                scores.game_id\n                , schedule.home_team\n                , scores.home_runs\n                , schedule.away_team\n                , scores.away_runs\n            from scores\n                left join schedule\n                on scores.game_id=schedule.game_id\n            where schedule.season_id like '2025'\n        )\n        select\n            game_id\n            , teams.team_abbr\n            , dense_rank() over(order by home_team) as home_team\n            , dense_rank() over(order by away_team) as away_team\n            , home_runs\n            , away_runs\n            , (case\n                when home_runs > away_runs then 1\n                else 0\n            end) as home_win\n        from a\n            left join teams\n                on a.home_team=teams.team_id\n        where teams.season_id like '2025'\n        \"\"\"\n    )\n)\n```\n:::\n\n\n\n::: {#6 .cell execution_count=0}\n``` {.julia .cell-code}\n# Get a unique Dictionary of the team abbreviation and a team number that ranges from 1-30.\nids = Dict(Pair.(df.team_abbr, df.home_team))\n```\n:::\n\n\n\nNow, to define the simple Bradley-Terry model.\n\n$$\n\\begin{aligned}\ny \\sim \\text{Bernoulli}(\\theta) \\\\\n\\theta = \\frac{1}{1 + e^{-(log(\\alpha_\\text{home}) - log(\\alpha_\\text{away}))}} \\\\\n\\alpha_D \\sim \\mathcal{HN}(0, 1)\n\\end{aligned}\n$$\n\n::: {.panel-tabset}\n\n## `Stan`\n\n::: {#8 .cell execution_count=0}\n``` {.julia .cell-code}\n# The Stan model code.\nconst stan = \"\"\"\ndata {\n  int<lower=1> N; // Number of games.\n  int<lower=1> J; // Number of teams.\n  array[N, 2] int T; // Matrix of team ids.\n  array[N] int<lower=0, upper=1> y; // Did the home team win?\n}\n\ntransformed data {\n  // Create a vector indicating each team.\n  array[N] int away = to_array_1d(T[,1]);\n  array[N] int home = to_array_1d(T[,2]);\n}\n\nparameters {\n  vector[J] alpha; // The ability for each team.\n}\n\nmodel {\n  // Prior on a logged-odds scale of the ability for each team.\n  alpha ~ HalfNormal(0, 1);\n  // Compute the ability for each team given who won.\n  // The ability for the away team is dependent on whether they\n  // beat the home team.\n  // If the away team won, then the logged odd would be\n  // alpha_away * 1 - alpha_home * 0\n  y ~ bernoulli_logit(log(alpha[home]) - log(alpha[away]));\n}\n\ngenerated quantities {\n  // Compute the ranking of each team based on who won.\n  array[J] int rank; // Ranking of the teams.\n  {\n    // Get the ranking of each team in descending order\n    // of the alpha.\n    array[J] int rank_index = sort_indices_desc(alpha);\n    // For each team, apply the rank\n    // is the rank for team i.\n    for (i in 1:J) {\n      rank[rank_index[i]] = i;\n    }\n  }\n}\n\"\"\"\n```\n:::\n\n\n\n## `Turing.jl`\n\n::: {#10 .cell execution_count=0}\n``` {.julia .cell-code}\n# Define the model.\n@model function turing(x, y, d)\n    # Prior for the ability parameter\n    # for each team (length of d).\n    # HalfNormal.\n    α ~ filldist(truncated(Normal(0.,1.), 0., Inf), d)\n    # Likelihood.\n    for i in 1:length(y)\n        θ = log(α[x[i,1]]) - log(α[x[i,2]])\n        y[i] ~ BernoulliLogit(θ)\n    end\nend\n\n# Define the function to rank the teams.\n\"\"\"\n    rank\n\nRanking the ability scores, α, for each object in each posterior draw.\n\nArgs:\n    x (Chains): The result of sampling the turing.jl model.\n    d (Int8): The number of objects.\n\nReturns:\n\n\"\"\"\nfunction rank(x, d)\n    # Get the dims of the posterior.\n    iters = size(x,1)\n    chains = size(x,3)\n    # Create a matrix of samples for the α parameter.\n    samples = MCMCChains.group(x, :α).value\n    # Initialize an array of rankings.\n    rank_arr = Array{Integer, 3}(undef, iters, length(d), chains)\n    # Rank the α for each sample.\n    # This should produce an array with the ranking\n    # for each team -- in order.\n    for c in 1:chains\n        for i in 1:iters\n            # Get the current sample for iteration i and chain j\n            current_sample = samples[i, :, c]\n            # Rank the options by sorting the α values\n            # in descending order (higher α means higher rank).\n            ranked_indices = sortperm(current_sample, rev=true)\n            # Assign ranks to each option based on sorted order\n            for rank_idx in 1:length(d)\n                rank_arr[i, ranked_indices[rank_idx], c] = rank_idx\n            end\n        end\n    end\n    # Initialize a DataFrame.\n    df = DataFrame()\n    # Place the rankings into a DataFrame.\n    for c in 1:chains\n        for (key, value) in d\n            temp_df = DataFrame(\n                iter = repeat(iters:-1:1, outer=1)\n                , Rank = rank_arr[:, value, c]\n                , Team = key\n                , chain = c\n            )\n            # Append the temporary DataFrame\n            # to the main DataFrame\n            append!(df, temp_df)\n        end\n    end    \n    # Return the result.\n    return df\nend\n```\n:::\n\n\n:::\n\nNow, to fit the models.\n\n::: {.panel-tabset}\n\n## `Stan`\n\n## `Turing.jl`\n\n::: {#12 .cell execution_count=0}\n``` {.julia .cell-code}\nmod = turing(\n    Matrix(select(df, [:home_team, :away_team]))\n    , df.home_win\n    , length(ids)\n);\nfit = Turing.sample(mod, NUTS(), MCMCThreads(), 4_000, 4);\nturing_ranks = rank(fit, ids);\n```\n:::\n\n\n:::\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}